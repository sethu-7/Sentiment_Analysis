{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sethu-7/Sentimental_Analysis/blob/main/staticembeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIiefKuDgWR_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVk-Sg7sf9HY",
        "outputId": "94de8098-640d-4390-e632-7d9628200477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "PRBx1IebgM_t",
        "outputId": "1bd80247-0738-429f-d599-cf3b016c8c99"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b585c72b-18ef-402a-82b1-9185cd5a9630\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>12076615</td>\n",
              "      <td>RQ58W7SMO911M</td>\n",
              "      <td>0385730586</td>\n",
              "      <td>122662979</td>\n",
              "      <td>Sisterhood of the Traveling Pants (Book 1)</td>\n",
              "      <td>Books</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>this book was a great learning novel!</td>\n",
              "      <td>this boook was a great one that you could lear...</td>\n",
              "      <td>2005-10-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>12703090</td>\n",
              "      <td>RF6IUKMGL8SF</td>\n",
              "      <td>0811828964</td>\n",
              "      <td>56191234</td>\n",
              "      <td>The Bad Girl's Guide to Getting What You Want</td>\n",
              "      <td>Books</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Fun Fluff</td>\n",
              "      <td>If you are looking for something to stimulate ...</td>\n",
              "      <td>2005-10-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>12257412</td>\n",
              "      <td>R1DOSHH6AI622S</td>\n",
              "      <td>1844161560</td>\n",
              "      <td>253182049</td>\n",
              "      <td>Eisenhorn (A Warhammer 40,000 Omnibus)</td>\n",
              "      <td>Books</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>this isn't a review</td>\n",
              "      <td>never read it-a young relative idicated he lik...</td>\n",
              "      <td>2005-10-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>50732546</td>\n",
              "      <td>RATOTLA3OF70O</td>\n",
              "      <td>0373836635</td>\n",
              "      <td>348672532</td>\n",
              "      <td>Colby Conspiracy (Colby Agency)</td>\n",
              "      <td>Books</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>fine author on her A-game</td>\n",
              "      <td>Though she is honored to be Chicago Woman of t...</td>\n",
              "      <td>2005-10-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>51964897</td>\n",
              "      <td>R1TNWRKIVHVYOV</td>\n",
              "      <td>0262181533</td>\n",
              "      <td>598678717</td>\n",
              "      <td>The Psychology of Proof: Deductive Reasoning i...</td>\n",
              "      <td>Books</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Execellent cursor examination</td>\n",
              "      <td>Review based on a cursory examination by Unive...</td>\n",
              "      <td>2005-10-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b585c72b-18ef-402a-82b1-9185cd5a9630')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b585c72b-18ef-402a-82b1-9185cd5a9630 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b585c72b-18ef-402a-82b1-9185cd5a9630');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a25efb7-fa82-4b7b-b7c0-0095fbb8e054\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a25efb7-fa82-4b7b-b7c0-0095fbb8e054')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a25efb7-fa82-4b7b-b7c0-0095fbb8e054 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
              "0          US     12076615   RQ58W7SMO911M  0385730586       122662979   \n",
              "1          US     12703090    RF6IUKMGL8SF  0811828964        56191234   \n",
              "2          US     12257412  R1DOSHH6AI622S  1844161560       253182049   \n",
              "3          US     50732546   RATOTLA3OF70O  0373836635       348672532   \n",
              "4          US     51964897  R1TNWRKIVHVYOV  0262181533       598678717   \n",
              "\n",
              "                                       product_title product_category  \\\n",
              "0         Sisterhood of the Traveling Pants (Book 1)            Books   \n",
              "1      The Bad Girl's Guide to Getting What You Want            Books   \n",
              "2             Eisenhorn (A Warhammer 40,000 Omnibus)            Books   \n",
              "3                    Colby Conspiracy (Colby Agency)            Books   \n",
              "4  The Psychology of Proof: Deductive Reasoning i...            Books   \n",
              "\n",
              "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
              "0          4.0            2.0          3.0    N                 N   \n",
              "1          3.0            5.0          5.0    N                 N   \n",
              "2          4.0            1.0         22.0    N                 N   \n",
              "3          5.0            2.0          2.0    N                 N   \n",
              "4          4.0            0.0          2.0    N                 N   \n",
              "\n",
              "                         review_headline  \\\n",
              "0  this book was a great learning novel!   \n",
              "1                              Fun Fluff   \n",
              "2                    this isn't a review   \n",
              "3              fine author on her A-game   \n",
              "4          Execellent cursor examination   \n",
              "\n",
              "                                         review_body review_date  \n",
              "0  this boook was a great one that you could lear...  2005-10-14  \n",
              "1  If you are looking for something to stimulate ...  2005-10-14  \n",
              "2  never read it-a young relative idicated he lik...  2005-10-14  \n",
              "3  Though she is honored to be Chicago Woman of t...  2005-10-14  \n",
              "4  Review based on a cursory examination by Unive...  2005-10-14  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/amazon_reviews_us_Books_v1_02.tsv\",sep='\\t',on_bad_lines='skip')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "MQvc_IUfvUS4",
        "outputId": "29cf04fa-fc4d-428b-bad7-95acbfd3a0bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d6598d44-5965-42af-9723-7c760a02926f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.366844e+07</td>\n",
              "      <td>4.958554e+08</td>\n",
              "      <td>4.198500</td>\n",
              "      <td>9.328500</td>\n",
              "      <td>12.905700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.531824e+07</td>\n",
              "      <td>2.889539e+08</td>\n",
              "      <td>1.228678</td>\n",
              "      <td>26.490703</td>\n",
              "      <td>29.973029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.206538e+07</td>\n",
              "      <td>6.430000e+03</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.701130e+07</td>\n",
              "      <td>2.458308e+08</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.510044e+07</td>\n",
              "      <td>4.918668e+08</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.006822e+07</td>\n",
              "      <td>7.454314e+08</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.309657e+07</td>\n",
              "      <td>9.999939e+08</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1150.000000</td>\n",
              "      <td>1228.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6598d44-5965-42af-9723-7c760a02926f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6598d44-5965-42af-9723-7c760a02926f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6598d44-5965-42af-9723-7c760a02926f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b167a364-ac2c-427c-80cd-d6d1e7fff9f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b167a364-ac2c-427c-80cd-d6d1e7fff9f8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b167a364-ac2c-427c-80cd-d6d1e7fff9f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        customer_id  product_parent   star_rating  helpful_votes   total_votes\n",
              "count  1.000000e+04    1.000000e+04  10000.000000   10000.000000  10000.000000\n",
              "mean   3.366844e+07    4.958554e+08      4.198500       9.328500     12.905700\n",
              "std    1.531824e+07    2.889539e+08      1.228678      26.490703     29.973029\n",
              "min    1.206538e+07    6.430000e+03      1.000000       0.000000      0.000000\n",
              "25%    1.701130e+07    2.458308e+08      4.000000       2.000000      3.000000\n",
              "50%    3.510044e+07    4.918668e+08      5.000000       4.000000      6.000000\n",
              "75%    5.006822e+07    7.454314e+08      5.000000      10.000000     14.000000\n",
              "max    5.309657e+07    9.999939e+08      5.000000    1150.000000   1228.000000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=data.head(10000)\n",
        "data.head()\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO9hY_nzgSpc",
        "outputId": "005b06cd-e120-4f85-ac7c-fb6f238c53cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column(s) dropped successfully.\n",
            "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
            "0          US     12076615   RQ58W7SMO911M  0385730586       122662979   \n",
            "1          US     12703090    RF6IUKMGL8SF  0811828964        56191234   \n",
            "2          US     12257412  R1DOSHH6AI622S  1844161560       253182049   \n",
            "3          US     50732546   RATOTLA3OF70O  0373836635       348672532   \n",
            "4          US     51964897  R1TNWRKIVHVYOV  0262181533       598678717   \n",
            "\n",
            "                                       product_title product_category  \\\n",
            "0         Sisterhood of the Traveling Pants (Book 1)            Books   \n",
            "1      The Bad Girl's Guide to Getting What You Want            Books   \n",
            "2             Eisenhorn (A Warhammer 40,000 Omnibus)            Books   \n",
            "3                    Colby Conspiracy (Colby Agency)            Books   \n",
            "4  The Psychology of Proof: Deductive Reasoning i...            Books   \n",
            "\n",
            "   star_rating  helpful_votes  total_votes vine  \\\n",
            "0          4.0            2.0          3.0    N   \n",
            "1          3.0            5.0          5.0    N   \n",
            "2          4.0            1.0         22.0    N   \n",
            "3          5.0            2.0          2.0    N   \n",
            "4          4.0            0.0          2.0    N   \n",
            "\n",
            "                         review_headline  \\\n",
            "0  this book was a great learning novel!   \n",
            "1                              Fun Fluff   \n",
            "2                    this isn't a review   \n",
            "3              fine author on her A-game   \n",
            "4          Execellent cursor examination   \n",
            "\n",
            "                                         review_body review_date  \n",
            "0  this boook was a great one that you could lear...  2005-10-14  \n",
            "1  If you are looking for something to stimulate ...  2005-10-14  \n",
            "2  never read it-a young relative idicated he lik...  2005-10-14  \n",
            "3  Though she is honored to be Chicago Woman of t...  2005-10-14  \n",
            "4  Review based on a cursory examination by Unive...  2005-10-14  \n"
          ]
        }
      ],
      "source": [
        "column_to_drop = 'verified_purchase'\n",
        "matching_columns = [col for col in data.columns if col.strip().lower() == column_to_drop.strip().lower()]\n",
        "\n",
        "if len(matching_columns) == 0:\n",
        "    print(f\"Column '{column_to_drop}' not found in the DataFrame.\")\n",
        "else:\n",
        "    # Drop the column(s) with matching names\n",
        "    data.drop(columns=matching_columns, inplace=True)\n",
        "    print(\"Column(s) dropped successfully.\")\n",
        "\n",
        "# Display the first few rows of the modified DataFrame\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4qf_M8mgbbV"
      },
      "outputs": [],
      "source": [
        "data.dropna(subset=['review_body'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjh02WqCggHh",
        "outputId": "2c4df375-9f5c-46e9-ae3a-808bd85ad0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     marketplace  customer_id       review_id  product_id  product_parent  \\\n",
            "0             US     12076615   RQ58W7SMO911M  0385730586       122662979   \n",
            "1             US     12703090    RF6IUKMGL8SF  0811828964        56191234   \n",
            "2             US     12257412  R1DOSHH6AI622S  1844161560       253182049   \n",
            "3             US     50732546   RATOTLA3OF70O  0373836635       348672532   \n",
            "4             US     51964897  R1TNWRKIVHVYOV  0262181533       598678717   \n",
            "...          ...          ...             ...         ...             ...   \n",
            "9995          US     39463040  R3ERCMQAPGUPPO  000714119X       964876990   \n",
            "9996          US     12125562   RN3MKB8R1HO7S  0743276949       179955861   \n",
            "9997          US     50978465   R8AVT247L6OXS  0152003940       191557539   \n",
            "9998          US     49232576   R56N4U54NA53D  0821779524       880389301   \n",
            "9999          US     47974532  R2S21KSG1YF05D  0140139451       917687557   \n",
            "\n",
            "                                          product_title product_category  \\\n",
            "0            Sisterhood of the Traveling Pants (Book 1)            Books   \n",
            "1         The Bad Girl's Guide to Getting What You Want            Books   \n",
            "2                Eisenhorn (A Warhammer 40,000 Omnibus)            Books   \n",
            "3                       Colby Conspiracy (Colby Agency)            Books   \n",
            "4     The Psychology of Proof: Deductive Reasoning i...            Books   \n",
            "...                                                 ...              ...   \n",
            "9995  The Hitler/Hess Deception: British Intelligenc...            Books   \n",
            "9996  What Remains: A Memoir of Fate, Friendship, an...            Books   \n",
            "9997  Where, Oh Where, Is Kipper's Bear?: A Pop-Up B...            Books   \n",
            "9998                      Veiled Promises (Zebra Debut)            Books   \n",
            "9999       Deng Xiaoping and the Making of Modern China            Books   \n",
            "\n",
            "      star_rating  helpful_votes  total_votes vine  \\\n",
            "0             4.0            2.0          3.0    N   \n",
            "1             3.0            5.0          5.0    N   \n",
            "2             4.0            1.0         22.0    N   \n",
            "3             5.0            2.0          2.0    N   \n",
            "4             4.0            0.0          2.0    N   \n",
            "...           ...            ...          ...  ...   \n",
            "9995          2.0            3.0         14.0    N   \n",
            "9996          1.0           29.0         56.0    N   \n",
            "9997          5.0            0.0          0.0    N   \n",
            "9998          2.0           13.0         24.0    N   \n",
            "9999          5.0            9.0          9.0    N   \n",
            "\n",
            "                                        review_headline  \\\n",
            "0                 this book was a great learning novel!   \n",
            "1                                             Fun Fluff   \n",
            "2                                   this isn't a review   \n",
            "3                             fine author on her A-game   \n",
            "4                         Execellent cursor examination   \n",
            "...                                                 ...   \n",
            "9995  The Hitler Hess Deception - only good up to a ...   \n",
            "9996                                  Dissappointing...   \n",
            "9997                                         Great Book   \n",
            "9998                            How to Torture A Reader   \n",
            "9999                Excellent, truly valuable biography   \n",
            "\n",
            "                                            review_body review_date sentiment  \n",
            "0     this boook was a great one that you could lear...  2005-10-14  positive  \n",
            "1     If you are looking for something to stimulate ...  2005-10-14   neutral  \n",
            "2     never read it-a young relative idicated he lik...  2005-10-14  positive  \n",
            "3     Though she is honored to be Chicago Woman of t...  2005-10-14  positive  \n",
            "4     Review based on a cursory examination by Unive...  2005-10-14  positive  \n",
            "...                                                 ...         ...       ...  \n",
            "9995  So good it could have been written by MI5. A v...  2005-10-08  negative  \n",
            "9996  Even though Carole went through some painful t...  2005-10-08  negative  \n",
            "9997  My twin boys love this book....especially the ...  2005-10-08  positive  \n",
            "9998  As a writer aspiring to be published myself th...  2005-10-08  negative  \n",
            "9999  I enjoyed enormously this book: it doesnt try ...  2005-10-08  positive  \n",
            "\n",
            "[10000 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define a function to map star ratings to sentiment categories\n",
        "def map_rating_to_sentiment(rating):\n",
        "    if rating >= 4.0:\n",
        "        return 'positive'\n",
        "    elif rating <= 2.0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Apply the mapping function to create the 'sentiment' column\n",
        "data['sentiment'] = data['star_rating'].apply(map_rating_to_sentiment)\n",
        "\n",
        "# Now 'data' DataFrame contains the 'sentiment' column based on the mapping of 'star_rating'\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SwigZnjWgvJ7",
        "outputId": "ac568a17-d6fd-4e86-9f87-da09f927a6e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using tfidf embedding and svm is: 0.8245\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Load CSV data using pandas\n",
        "# csv_path = 'path_to_your_csv_file.csv'\n",
        "# data = pd.read_csv(csv_path)\n",
        "\n",
        "# Assuming your CSV has 'text' column and 'label' column\n",
        "texts = data['review_body']\n",
        "labels = data['sentiment']\n",
        "\n",
        "# Manually split the data into training and testing sets\n",
        "split_ratio = 0.8  # 80% for training, 20% for testing\n",
        "split_index = int(len(texts) * split_ratio)\n",
        "train_texts, test_texts = texts[:split_index], texts[split_index:]\n",
        "train_labels, test_labels = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Create TF-IDF vectors from text data\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
        "test_tfidf = tfidf_vectorizer.transform(test_texts)\n",
        "\n",
        "# Train an SVM model using scikit-learn\n",
        "svm_model = SVC(kernel='linear', C=1.0)\n",
        "svm_model.fit(train_tfidf, train_labels)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = svm_model.predict(test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy using tfidf embedding and svm is:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsHS4LY9hm0h",
        "outputId": "1ff256a1-f77c-406d-b2c7-ac1c3b307a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using word to vec embedding and svm model is: 0.80\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Load CSV data\n",
        "# data = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assuming your CSV has 'text' and 'label' columns\n",
        "texts = data['review_body'].tolist()\n",
        "labels = data['sentiment'].tolist()\n",
        "\n",
        "# Manually split the data into training and testing sets\n",
        "split_ratio = 0.8  # 80% for training, 20% for testing\n",
        "split_index = int(len(texts) * split_ratio)\n",
        "train_texts, test_texts = texts[:split_index], texts[split_index:]\n",
        "train_labels, test_labels = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Word2Vec embedding\n",
        "tokenized_texts = [text.split() for text in train_texts + test_texts]\n",
        "embedding_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, sg=1)  # Adjust parameters\n",
        "\n",
        "# Function to average word vectors for a text\n",
        "def average_word_vectors(words, model):\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    if not vectors:\n",
        "        return [0] * model.vector_size\n",
        "    return sum(vectors) / len(vectors)\n",
        "\n",
        "# Apply Word2Vec embedding to training and test data\n",
        "train_embeddings = [average_word_vectors(text.split(), embedding_model) for text in train_texts]\n",
        "test_embeddings = [average_word_vectors(text.split(), embedding_model) for text in test_texts]\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "train_encoded_labels = label_encoder.fit_transform(train_labels)\n",
        "test_encoded_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "# Train an SVM model\n",
        "svm_model = SVC(kernel='linear')  # You can adjust the kernel and other hyperparameters\n",
        "svm_model.fit(train_embeddings, train_encoded_labels)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = svm_model.predict(test_embeddings)\n",
        "\n",
        "# Convert numerical predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(f\"Accuracy using word2vec embedding and svm model is: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAeCs7cu1SYe",
        "outputId": "b95cd615-fd44-45bd-a23a-d1a3d0614ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using word2vec and naive bayes mdoel is: 0.80\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Load CSV data\n",
        "# data = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assuming your CSV has 'text' and 'label' columns\n",
        "texts = data['review_body'].tolist()\n",
        "labels = data['sentiment'].tolist()\n",
        "\n",
        "# Manually split data into train and test sets\n",
        "split_ratio = 0.8\n",
        "split_idx = int(len(texts) * split_ratio)\n",
        "\n",
        "train_texts = texts[:split_idx]\n",
        "test_texts = texts[split_idx:]\n",
        "train_labels = labels[:split_idx]\n",
        "test_labels = labels[split_idx:]\n",
        "\n",
        "# Apply Word2Vec embedding to training and test data\n",
        "train_embeddings = [average_word_vectors(text.split(), embedding_model) for text in train_texts]\n",
        "test_embeddings = [average_word_vectors(text.split(), embedding_model) for text in test_texts]\n",
        "train_embeddings=np.abs(train_embeddings)\n",
        "test_embeddings=np.abs(test_embeddings)\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "train_encoded_labels = label_encoder.fit_transform(train_labels)\n",
        "test_encoded_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "# Train a Multinomial Naive Bayes model\n",
        "naive_bayes_model = MultinomialNB()\n",
        "naive_bayes_model.fit(train_embeddings, train_encoded_labels)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = naive_bayes_model.predict(test_embeddings)\n",
        "\n",
        "# Convert numerical predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(f\"Accuracy using word2vec and naive bayes mdoel is: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq1NPOCZ4XNT",
        "outputId": "d6638472-4900-4b01-c2bf-8b90aa9c70d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using word2vec and rf: 0.7975\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Load CSV data\n",
        "# data = pd.read_csv('your_data.csv')\n",
        "\n",
        "# # Assuming your CSV has 'text' and 'label' columns\n",
        "# texts = data['text'].tolist()\n",
        "# labels = data['label'].tolist()\n",
        "\n",
        "# # Manually split data into train and test sets\n",
        "# split_ratio = 0.8\n",
        "# split_idx = int(len(texts) * split_ratio)\n",
        "\n",
        "# train_texts = texts[:split_idx]\n",
        "# test_texts = texts[split_idx:]\n",
        "# train_labels = labels[:split_idx]\n",
        "# test_labels = labels[split_idx:]\n",
        "\n",
        "# Word2Vec embedding\n",
        "tokenized_texts = [text.split() for text in train_texts + test_texts]\n",
        "embedding_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, sg=1)  # Adjust parameters\n",
        "\n",
        "# Function to average word vectors for a text\n",
        "def average_word_vectors(words, model):\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    if not vectors:\n",
        "        return [0] * model.vector_size\n",
        "    return sum(vectors) / len(vectors)\n",
        "\n",
        "# Apply Word2Vec embedding to training and test data\n",
        "train_embeddings = [average_word_vectors(text.split(), embedding_model) for text in train_texts]\n",
        "test_embeddings = [average_word_vectors(text.split(), embedding_model) for text in test_texts]\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "train_encoded_labels = label_encoder.fit_transform(train_labels)\n",
        "test_encoded_labels = label_encoder.transform(test_labels)\n",
        "\n",
        "# Train a Random Forest model\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100)  # You can adjust the number of estimators\n",
        "random_forest_model.fit(train_embeddings, train_encoded_labels)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = random_forest_model.predict(test_embeddings)\n",
        "\n",
        "# Convert numerical predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(f\"Accuracy using word2vec and rf: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD3gIcgq52n1",
        "outputId": "d7fe9c83-f869-4814-d3c1-d94d8d315919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7950\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load FastText pre-trained word vectors from .vec file\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/wiki-news-300d-1M.vec')\n",
        "\n",
        "# Load CSV data\n",
        "# data = []\n",
        "# labels = []\n",
        "# with open('data.csv', 'r') as csvfile:\n",
        "#     reader = csv.reader(csvfile)\n",
        "#     next(reader)  # Skip header\n",
        "#     for row in reader:\n",
        "#         labels.append(int(row[0]))  # Assuming label is in the first column\n",
        "#         text = row[1]  # Assuming text data is in the second column\n",
        "#         data.append(text)\n",
        "\n",
        "# # Manually split data into training and testing sets\n",
        "# split_ratio = 0.8\n",
        "# split_index = int(split_ratio * len(data))\n",
        "# train_data, test_data = data[:split_index], data[split_index:]\n",
        "# train_labels, test_labels = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Generate FastText embeddings for the data\n",
        "def text_to_embedding(text):\n",
        "    words = text.split()\n",
        "    embeddings = [fasttext_model[word] for word in words if word in fasttext_model]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    return np.zeros(fasttext_model.vector_size)\n",
        "\n",
        "train_embeddings = np.array([text_to_embedding(text) for text in train_texts])\n",
        "test_embeddings = np.array([text_to_embedding(text) for text in test_texts])\n",
        "\n",
        "# Train an SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0)\n",
        "svm_model.fit(train_embeddings, train_labels)\n",
        "\n",
        "# Make predictions\n",
        "predictions = svm_model.predict(test_embeddings)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(f\"Accuracy using fast text and svm: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tazr3pRqN7mB",
        "outputId": "f4b353f0-4421-4704-eb30-94a0e0f86637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using fast text embeddings and naive bayes model: 0.80\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load FastText pre-trained word vectors from .vec file\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/wiki-news-300d-1M.vec')\n",
        "\n",
        "# # Load CSV data\n",
        "# data = []\n",
        "# labels = []\n",
        "# with open('data.csv', 'r') as csvfile:\n",
        "#     reader = csv.reader(csvfile)\n",
        "#     next(reader)  # Skip header\n",
        "#     for row in reader:\n",
        "#         labels.append(int(row[0]))  # Assuming label is in the first column\n",
        "#         text = row[1]  # Assuming text data is in the second column\n",
        "#         data.append(text)\n",
        "\n",
        "# # Manually split data into training and testing sets\n",
        "# split_ratio = 0.8\n",
        "# split_index = int(split_ratio * len(data))\n",
        "# train_data, test_data = data[:split_index], data[split_index:]\n",
        "# train_labels, test_labels = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Generate FastText embeddings for the data\n",
        "def text_to_embedding(text):\n",
        "    words = text.split()\n",
        "    embeddings = [fasttext_model[word] for word in words if word in fasttext_model]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    return np.zeros(fasttext_model.vector_size)\n",
        "\n",
        "train_embeddings = np.array([text_to_embedding(text) for text in train_texts])\n",
        "test_embeddings = np.array([text_to_embedding(text) for text in test_texts])\n",
        "\n",
        "# Convert embeddings to count-based features (not the most suitable, but for illustrative purposes)\n",
        "train_features = np.array([[int(value) for value in row] for row in train_embeddings])\n",
        "test_features = np.array([[int(value) for value in row] for row in test_embeddings])\n",
        "\n",
        "# Train a Multinomial Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(train_features, train_labels)\n",
        "\n",
        "# Make predictions\n",
        "predictions = nb_model.predict(test_features)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(f\"Accuracy using fast text embeddings and naive bayes model: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hgEcVjHTCZU",
        "outputId": "2f5fa249-9409-48bc-ed60-f19be400eba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using fast text embeddingsa nd rf model: 0.80\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load FastText pre-trained word vectors from .vec file\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/wiki-news-300d-1M.vec')\n",
        "\n",
        "# # Load CSV data\n",
        "# data = []\n",
        "# labels = []\n",
        "# with open('data.csv', 'r') as csvfile:\n",
        "#     reader = csv.reader(csvfile)\n",
        "#     next(reader)  # Skip header\n",
        "#     for row in reader:\n",
        "#         labels.append(int(row[0]))  # Assuming label is in the first column\n",
        "#         text = row[1]  # Assuming text data is in the second column\n",
        "#         data.append(text)\n",
        "\n",
        "# # Manually split data into training and testing sets\n",
        "# split_ratio = 0.8\n",
        "# split_index = int(split_ratio * len(data))\n",
        "# train_data, test_data = data[:split_index], data[split_index:]\n",
        "# train_labels, test_labels = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Generate FastText embeddings for the data\n",
        "def text_to_embedding(text):\n",
        "    words = text.split()\n",
        "    embeddings = [fasttext_model[word] for word in words if word in fasttext_model]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    return np.zeros(fasttext_model.vector_size)\n",
        "\n",
        "train_embeddings = np.array([text_to_embedding(text) for text in train_texts])\n",
        "test_embeddings = np.array([text_to_embedding(text) for text in test_texts])\n",
        "\n",
        "# Train a Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(train_embeddings, train_labels)\n",
        "\n",
        "# Make predictions\n",
        "predictions = rf_model.predict(test_embeddings)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(f\"Accuracy using fast text embeddingsa nd rf model: {accuracy:.4ff}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TYnZY5UmHPYc",
        "outputId": "56acf327-b719-435b-bac0-3543d37160f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8035\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# # Load CSV data\n",
        "# csv_path = \"path_to_your_csv_file.csv\"\n",
        "# data = pd.read_csv(csv_path)\n",
        "\n",
        "# # Assuming your CSV has 'text' and 'label' columns\n",
        "# texts = data['text']\n",
        "# labels = data['label']\n",
        "\n",
        "# # Manually split data into training and testing sets\n",
        "# train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_path = \"/content/drive/MyDrive/glove.42B.300d.txt\"\n",
        "\n",
        "word_vectors = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.split()\n",
        "        word = parts[0]\n",
        "        embedding = np.array(parts[1:], dtype=np.float32)\n",
        "        word_vectors[word] = embedding\n",
        "\n",
        "# Convert texts to GloVe embeddings\n",
        "embedding_dim = 300  # Change this according to your GloVe embedding dimension\n",
        "train_embeddings = []\n",
        "test_embeddings = []\n",
        "\n",
        "for text in train_texts:\n",
        "    words = text.split()\n",
        "    embeddings = [word_vectors.get(word, np.zeros(embedding_dim)) for word in words]\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    train_embeddings.append(avg_embedding)\n",
        "\n",
        "for text in test_texts:\n",
        "    words = text.split()\n",
        "    embeddings = [word_vectors.get(word, np.zeros(embedding_dim)) for word in words]\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    test_embeddings.append(avg_embedding)\n",
        "\n",
        "train_embeddings = np.array(train_embeddings)\n",
        "test_embeddings = np.array(test_embeddings)\n",
        "\n",
        "# Train SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0)\n",
        "svm_model.fit(train_embeddings, train_labels)\n",
        "\n",
        "# Evaluate SVM model\n",
        "accuracy = svm_model.score(test_embeddings, test_labels)\n",
        "print(\"Accuracy using glove and svm:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbCHg3F-K2aR",
        "outputId": "628f186f-4a11-4b10-a0da-302cf853b6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using glove and naive bayes: 0.795\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# # Load CSV data\n",
        "# csv_path = \"path_to_your_csv_file.csv\"\n",
        "# data = pd.read_csv(csv_path)\n",
        "\n",
        "# # Assuming your CSV has 'text' and 'label' columns\n",
        "# texts = data['text']\n",
        "# labels = data['label']\n",
        "\n",
        "# # Manually split data into training and testing sets\n",
        "# train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_path = \"/content/drive/MyDrive/glove.42B.300d.txt\"\n",
        "\n",
        "word_vectors = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.split()\n",
        "        word = parts[0]\n",
        "        embedding = np.array(parts[1:], dtype=np.float32)\n",
        "        word_vectors[word] = embedding\n",
        "\n",
        "# Convert texts to GloVe embeddings\n",
        "embedding_dim = 300  # Change this according to your GloVe embedding dimension\n",
        "train_embeddings = []\n",
        "test_embeddings = []\n",
        "\n",
        "for text in train_texts:\n",
        "    words = text.split()\n",
        "    embeddings = [word_vectors.get(word, np.zeros(embedding_dim)) for word in words]\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    train_embeddings.append(avg_embedding)\n",
        "\n",
        "for text in test_texts:\n",
        "    words = text.split()\n",
        "    embeddings = [word_vectors.get(word, np.zeros(embedding_dim)) for word in words]\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    test_embeddings.append(avg_embedding)\n",
        "\n",
        "train_embeddings = np.array(train_embeddings)\n",
        "test_embeddings = np.array(test_embeddings)\n",
        "train_embeddings=np.abs(train_embeddings)\n",
        "test_embeddings=np.abs(test_embeddings)\n",
        "\n",
        "# Train Naive Bayes modele\n",
        "naive_bayes_model = MultinomialNB()\n",
        "naive_bayes_model.fit(train_embeddings, train_labels)\n",
        "\n",
        "# Evaluate Naive Bayes model\n",
        "accuracy = naive_bayes_model.score(test_embeddings, test_labels)\n",
        "print(\"Accuracy using glove and naive bayes:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_43qjADOaxd",
        "outputId": "373203e5-a6d1-4225-f454-4435335f9f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using glove and rf model: 0.796\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# # Load CSV data\n",
        "# csv_path = \"path_to_your_csv_file.csv\"\n",
        "# data = pd.read_csv(csv_path)\n",
        "\n",
        "# # Assuming your CSV has 'text' and 'label' columns\n",
        "# texts = data['text']\n",
        "# labels = data['label']\n",
        "\n",
        "# # Manually split data into training and testing sets\n",
        "# train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_path = \"/content/drive/MyDrive/glove.42B.300d.txt\"\n",
        "\n",
        "word_vectors = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.split()\n",
        "        word = parts[0]\n",
        "        embedding = np.array(parts[1:], dtype=np.float32)\n",
        "        word_vectors[word] = embedding\n",
        "\n",
        "# Convert texts to GloVe embeddings\n",
        "embedding_dim = 300  # Change this according to your GloVe embedding dimension\n",
        "train_embeddings = []\n",
        "test_embeddings = []\n",
        "\n",
        "for text in train_texts:\n",
        "    words = text.split()\n",
        "    embeddings = [word_vectors.get(word, np.zeros(embedding_dim)) for word in words]\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    train_embeddings.append(avg_embedding)\n",
        "\n",
        "for text in test_texts:\n",
        "    words = text.split()\n",
        "    embeddings = [word_vectors.get(word, np.zeros(embedding_dim)) for word in words]\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    test_embeddings.append(avg_embedding)\n",
        "\n",
        "train_embeddings = np.array(train_embeddings)\n",
        "test_embeddings = np.array(test_embeddings)\n",
        "train_embeddings=np.abs(train_embeddings)\n",
        "test_embeddings=np.abs(test_embeddings)\n",
        "\n",
        "# Train Random Forest model\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(train_embeddings, train_labels)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "accuracy = random_forest_model.score(test_embeddings, test_labels)\n",
        "print(\"Accuracy using glove and rf model:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lsrR57cOmGu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGpZix9Mc4HgjdYrFCmKbc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}